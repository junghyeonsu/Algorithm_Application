{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PCA .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPCZ2Gl0hFx64ghNOz6ADNS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/junghyeonsu/Algorithm_Application/blob/master/PCA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ss2BBVk-5hK",
        "colab_type": "text"
      },
      "source": [
        "# PCA (principal component analysis)\n",
        "\n",
        "\n",
        "## PCA는 왜 중요할까?\n",
        "\n",
        "우리는 다양하고 많은 양의 데이터가 존재하는 세상에서 살고있다.\n",
        "\n",
        "정말 많은 양의 데이터를 그 데이터가 담고있는 속성을 그대로 유지하면서 데이터의 양을 줄일수 있을까?\n",
        "\n",
        "PCA와 함께라면 가능하다.\n",
        "\n",
        "PCA가 없다면 어떻게 될까?\n",
        "\n",
        "우리는 많은 양의 데이터를 가공할 때 모든 데이터를 사용해야 하기 때문에 많은 시간이 걸릴 것이다.\n",
        "\n",
        "PCA가 존재함으로써 그 불상사를 막을 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4YvzcelBBZP",
        "colab_type": "text"
      },
      "source": [
        "## PCA는 일상생활에 어떻게 적용될까?\n",
        "\n",
        "PCA는 차원축소 기법으로써, 많은 양의 데이터를 속성을 유지하면서 적은 양의 데이터로 변환 시켜준다.\n",
        "\n",
        "PCA는 우선 데이터의 효율성을 높여준다.\n",
        "그리고 시각화를 할 수 있게 해준다.\n",
        "\n",
        "우리가 실무에서 쓰는 데이터들은 엄청나게 많은 컬럼들로 이루어져있다. 이것들을 시각화를 하려고하면 시간도 엄청 오래걸리고 효율도 엄청 떨어지기 때문에 좋지않다. 하지만 PCA를 적용시켜 데이터 차원을 축소시킨다면, 2차원데이터를 시각화 하는것은 정말 쉽기 때문에 시각화에 도움이 되고, 용량 또한 줄어들고 머신러닝의 효율성이 올라간다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ay15hvvWDKkE",
        "colab_type": "text"
      },
      "source": [
        "## 분석 알고리즘\n",
        "\n",
        "PCA가 분석기법의 한 알고리즘으로써,\n",
        "다른 많은 알고리즘들이 존재한다.\n",
        "\n",
        "예를들면\n",
        "* PCA (principal component analysis)\n",
        "* LDA (Linear discriminant analysis)\n",
        "* Autoencoder\n",
        "* t-SNE\n",
        "* UMAP.. \n",
        "\n",
        "등등 그렇지만 오늘은 PCA만 다루기 때문에\n",
        "PCA만 다루도록 하겠다.\n",
        "\n",
        "PCA를 도와주는 패키지 혹은 라이브러리는 \n",
        "정말 유명한 sklearn 패키지에서 sklearn.decomposition.PCA 라는 라이브러리를 쓸 수 있다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_tVR-tNDy34",
        "colab_type": "text"
      },
      "source": [
        "## 그러면 PCA는 어떻게 이루어질까?\n",
        "\n",
        "PCA의 과정은 크게 세가지로 이루어진다\n",
        "1. Linear Projection\n",
        "\n",
        "2. Basis Change\n",
        "\n",
        "3. Minimize Redundancy\n",
        "\n",
        "### Linear projection\n",
        "Linear projection은 선형 변환이다.\n",
        "간단히 rotation하고, stretch하는 것이 Linear projection이라고 할 수 있다.\n",
        "\n",
        "말 그대로 축을 바꾸는 것인데 축을 바꿀 때 가장 중요한 것은 데이터들을 설명하는 컴포넌트끼리의 **정보 중복성**을 줄여주는 방향으로 축을 바꿔주어야 한다.\n",
        "\n",
        "\n",
        "### Basis change\n",
        "\n",
        "Basis는 기저 벡터로써, 기본적인 벡터 즉, 단위 벡터라고 이해를 하면 된다.\n",
        "\n",
        "2차원이라면 x,y축에 대한 단위벡터가 Basis 라고 생각하면 된다.\n",
        "\n",
        "\n",
        "Basis change는 뭘까? \n",
        "\n",
        "![image](https://user-images.githubusercontent.com/54893898/83751914-9bfa3400-a6a2-11ea-98b8-2e34bca73ef4.png)\n",
        "\n",
        "원래 데이터 셋인 X가 있다면 새로운 데이터 셋인 Y로 변환하고 싶다면 우리가 P Matrix(선형변환)를 곱해줌으로써 현상을 더 잘 설명할 수 있는 데이터 축을 찾는 것이다! \n",
        "\n",
        "말 그대로 축을 변환시켜 더 좋은 데이터 축으로 바꾸는 것이 Basis change의 기본 원리! \n",
        "\n",
        "### Minimize Redundancy\n",
        "\n",
        "축을 바꾸고 나서 데이터 셋을 봤을 때 이제 중복성을 최소화 시켜주는 작업만 하면 차원축소의 모든 단계가 끝이난다.\n",
        "\n",
        "#### 중복성을 최소화?\n",
        "\n",
        "![image](https://user-images.githubusercontent.com/54893898/83752422-7c174000-a6a3-11ea-9a85-745e51c393da.png)\n",
        "\n",
        "만약 A 컴포넌트와 D 컴포넌트를 봤을 때\n",
        "데이터의 흐름이 A가 오를 때 D도 같이 오르고, \n",
        "\n",
        "요기서 오른다는 것은 꼭 같은 양으로 올라야 한다는 것이 아니고, 흐름만 비슷하면 된다. \n",
        "\n",
        "컴포넌트들의 흐름이 비슷하면 그 두 컴포넌트는 데이터를 표시하는데 전부다 표시해 줄 필요는 없다는 것을 의미한다.\n",
        "\n",
        "그러면 둘 중 하나의 데이터만 표시해주면 된다.\n",
        "\n",
        "근데 그게아니고 둘의 컴포넌트가 만약 관계가 많지 않다면, A,D 컴포넌트 둘다 데이터를 표시하는데 각각 중요한 역할을 한다고 생각할 수 있다.\n",
        "\n",
        "#### 그래서 우리는 변화율을 보면 된다.\n",
        "\n",
        "각각 컴포넌트끼리의 변하는 정도를 나타내주는 Covariance matrix를 만들어 주어 각각 컴포넌트들의 변화율을 한눈에 보기 좋게 표시한다.\n",
        "\n",
        "그러면 어느 컴포넌트를 써야할지 바로 볼 수 있는 것이다.\n",
        "\n",
        "그렇게 만들어진 Covariance matrix에서 우리가 축소하기 원하는 차원만큼만 Covariance matrix의 컴포넌트를 남기고, \n",
        "\n",
        "원래 데이터 셋과 곱해주면 우리가 원하는 차원이 축소되고 원래 데이터의 성질을 가지고 있는 새로운 Y 매트릭스가 완성이 된다.\n",
        "\n",
        "![image](https://user-images.githubusercontent.com/54893898/83753189-ce0c9580-a6a4-11ea-8bd2-d774e409d286.png)\n",
        "\n",
        "지금까지 말한 과정을 시각화한 자료이다.\n",
        "\n",
        "출처 : [충남대학교 정상근 교수님 PCA 교육 자료 (알고리즘 응용)]\n"
      ]
    }
  ]
}