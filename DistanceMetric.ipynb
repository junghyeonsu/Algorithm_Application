{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DistanceMetric.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMhxuPvy1vFoptP3ldXXHvV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/junghyeonsu/Algorithm_Application/blob/master/DistanceMetric.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hN5Ri9rOmcXw",
        "colab_type": "text"
      },
      "source": [
        "# Distance Metric이란?\n",
        "\n",
        "Machine Learning 분야에는 KNN 등의 input data의 distance metric을 어떻게 설정하냐 따라에 크게 영향을 받는 알고리듬들이 종종 존재한다. \n",
        "\n",
        "그런데, 대부분 이런 method들에서 주로 사용하는 distance metric은 Euclidean distance로, 이 metric은 근본적으로 데이터 하나와 다른 데이터 하나와의 관계만을 나타내기 때문에 실제 distribution으로 존재하는 데이터에는 적합하지 않은 경우가 많다. \n",
        "\n",
        "**때문에 데이터들의 분포 등을 고려하여 이런 ‘거리’를 새로 정의하는 분야가 존재하는데 이를 일컬어 Distance Metric Learning이라 한다.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGsIThvlo3ww",
        "colab_type": "text"
      },
      "source": [
        "# Distance Metric이 중요한 이유?\n",
        "\n",
        "우리가 Distance라고 말하면 그냥 어떤 점과 어떤 점 사이의 거리만 생각할 수 있다.\n",
        "\n",
        "그렇지만 우리가 적용할 수 있는  Distance Metric은 정말 다양한 분야에 적용을 할 수 있다.\n",
        "\n",
        "어떤 집단과 하나의 개체에 대한 거리, 혹은 어떤 집단과 어떤 집단에 대한 거리,\n",
        "\n",
        "혹은 어느 단어가 어떤 단어로 변하는데 필요한 거리 등등 수많은 곳에서 이용되는 \n",
        "\n",
        "분야이기 때문에 중요한 분야라고 할 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtwFkaDUwVy2",
        "colab_type": "text"
      },
      "source": [
        "#Distance Metric이 일상생활에서 쓰이는곳?\n",
        "\n",
        "distance metric learning은 input data space에서 data들에 가장 적합한 형태의 어떤 metric을 learning하는 알고리듬이다. 여기에서 data는 각 pair 별로 similar/dissimilar가 정의되어 있는 형태의 데이터이다. 즉, metric learning은 similar한 point끼리는 더 가까운 거리로 판단하게 하고, dissimilar한 point는 더 먼 거리로 판단하게 하는 어떤 metric을 학습하는 것이다. 당연히 KNN 등의 알고리듬들은 그 성능이 크게 개선될 수 있다.\n",
        "\n",
        "출처:[http://sanghyukchun.github.io/37/]\n",
        "\n",
        "위에서 보면 거리 = 유사성으로 생각해도 된다. 유사성을 따지는 모든 분야에 적용할 수 있는 것이다.\n",
        "\n",
        "예를들면 문서조작을 방지하기 위해 방지프로그램을 짤 때, 카피가 안된 문서들의 집단과 학생들이 제출한 문서를 비교를 한다음 유사성을 거리공식을 이용해 구해서 카피인지 아닌지 확인하는 그런 방식으로도 쓸 수 있다.\n",
        "\n",
        "혹은 어떤 사람이 쓴 단어를 보고 어느 쪽 단어에 더 가까운지 유사성을 따지는 그런 용도로도 쓸 수 있다.\n",
        "\n",
        "유사성을 이용한 분야는 이것말고도 너무 넘쳐나기 때문에 잘만 이용한다면 정말 다양한 분야에 쓸 수 있을 것이다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqs0eMI6qFTa",
        "colab_type": "text"
      },
      "source": [
        "# Distance Metric이 활용가능한 주요 분야와 그 알고리즘들과 핵심 아이디어\n",
        "\n",
        "## 유클라디안 거리 (Euclidean Distance)\n",
        "\n",
        "유클라디안 거리 공식은 우리가 중학교때 배운 피타고라스를 생각하면 쉽다.\n",
        "\n",
        "![image](https://user-images.githubusercontent.com/54893898/83625292-ac40df00-a5ce-11ea-8fc8-fcfc1f07f322.png)\n",
        "\n",
        "![image](https://user-images.githubusercontent.com/54893898/83625279-a6e39480-a5ce-11ea-9809-e4d9e9cec1c7.png)\n",
        "\n",
        "출처 : [http://hleecaster.com/ml-distance-formula/]\n",
        "\n",
        "## 맨하탄 거리 (Manhattan Distance)\n",
        "\n",
        "![image](https://user-images.githubusercontent.com/54893898/83624895-30df2d80-a5ce-11ea-9aa5-332d7ea6081c.png)\n",
        "\n",
        "![image](https://user-images.githubusercontent.com/54893898/83625413-d85c6000-a5ce-11ea-9c36-7da1dafd490a.png)\n",
        "\n",
        "![image](https://user-images.githubusercontent.com/54893898/83625424-dbefe700-a5ce-11ea-9c99-b3fa53df43d9.png)\n",
        "\n",
        "출처 : [https://www.forbes.com/sites/forbesrealestatecouncil/2019/03/12/why-smart-investors-are-bullish-on-manhattan-real-estate/#790bcd446210]\n",
        "\n",
        "맨하탄의 거리는 바둑판 형식으로 점과 점사이의 거리 공식이 먹히지않는다.\n",
        "\n",
        "그렇기 때문에 맨하탄 전용 공식이 생겨났다.\n",
        "\n",
        "맨하탄을 계산해주는 파이썬 전용 라이브러리는\n",
        "\n",
        "Sklearn 혹은 Scipy가 제공해주는 Manhattan Distance 공식이 있다.\n",
        "\n",
        "\n",
        "# 마할라노비스 거리 (Mahalanobis distance) \n",
        "\n",
        "![image](https://user-images.githubusercontent.com/54893898/83625960-ba432f80-a5cf-11ea-931a-b8e8c69cd616.png)\n",
        "\n",
        "마할라노비스의 공식이다.\n",
        "\n",
        "마할라노비스 거리 공식을 알려면 놈(Norm)과 correlation 개념에 대해서 알아야한다.\n",
        "\n",
        "###놈(Norm)이란 일종의 함수이다.\n",
        "\n",
        "하나의 공간이 있으면 그 공간을 표현하고있는 점이있다.\n",
        "근데 그 공간에 함수를 씌우면 다른 벡터 스페이스가 나온다.\n",
        "\n",
        "그 중에 3가지를 만족하는 함수 = Norm 이라고 부른다.\n",
        "\n",
        "3가지 조건은 \n",
        "\n",
        "    1. Zero vector이다.\n",
        "    2. 스칼라 factor 이다. \n",
        "    3. Triangle inequality 이다. (피타고라스를 생각하면 된다)\n",
        "\n",
        "이 세가지를 동시에 만족하면 Norm 이다.\n",
        "\n",
        "### Correlation은 관계성이라고 생각하면된다.\n",
        "\n",
        "x가 커질 때, y도 커진다. (positive correlation)\n",
        "그럼 x 와 y는 코렐레이션을 가진다.\n",
        "\n",
        "근데 x가 작아질때, y는 커진다\n",
        "이것 또한 코렐레이션이 있다. (negative correlation)\n",
        "\n",
        "데이터는 벡터 폼으로 표현할수있다. (컴포넌트들의 모음으로 표현할수있다.)\n",
        "ex) x1, x2, x3 .....\n",
        "\n",
        "근데 x1이 바뀔 때\n",
        "x2가 바뀌나? x3가 바뀌나를 알고싶을 때 correlation을 보면된다.\n",
        "\n",
        "\n",
        "출처: [https://rfriend.tistory.com/tag/마할라노비스]\n"
      ]
    }
  ]
}