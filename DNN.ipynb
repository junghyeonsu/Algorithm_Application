{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNy6WvKySRIXmTQ3Ne6iTo+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/junghyeonsu/Algorithm_Application/blob/master/DNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWgmBslgCxBi",
        "colab_type": "text"
      },
      "source": [
        "# Deep Neural Network (DNN)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKxxf-gKDEZ5",
        "colab_type": "text"
      },
      "source": [
        "## DNN은 왜 중요할까?\n",
        "\n",
        "우리는 사진을 보고 그 사진에 있는 물체가 어떤 물체인지 바로 알 수 있다. \n",
        "\n",
        "만약 사다리가 담겨있는 사진을 본다면 그 사다리가 철 사다리이든, 나무 사다리이든, 우리는 전부 사다리라고 생각할 수 있다.\n",
        "\n",
        "###그렇지만 컴퓨터의 경우 어떻게 할까?\n",
        "\n",
        "우리가 컴퓨터에게 많은 양의 사다리 사진을 보여주면서 컴퓨터에게 사다리라는 물체의 특징들, 속성들을 학습시키는 것이다.\n",
        "\n",
        "우리가 직접 컴퓨터에게 알려주지 않아도 컴퓨터가 어떤 물체를 보고 바로 알수있게 하기 위한 머신러닝 방식으로, 우리 일상생활에 이제는 너무 많이 침투해있어서 없어서는 안되는 존재가 되어버렸다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwxob80nElfE",
        "colab_type": "text"
      },
      "source": [
        "##  우리 일상생활에 어떻게 적용되는지?\n",
        "\n",
        "심층 신경망 (DNN) 기법은 다양한 곳에서 쓰인다.\n",
        "\n",
        "자동음성인식기능, 혹은 우리 휴대폰의 얼굴인식기능과 같은 영상 인식 분야, 혹은 자연어 처리 분야, 심지어 약물 발견과 독성학에도 활용되고있다.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMwMUuFRFLFw",
        "colab_type": "text"
      },
      "source": [
        "# 활용가능한 주요 알고리즘의 이름, 패키지 명\n",
        "\n",
        "곽광받는 기술인 만큼 지원해주는 패키지들의 수가 엄청나다.\n",
        "\n",
        "* Theano - 수식 및 행렬 연산을 쉽게 만들어주는 파이썬 라이브러리. 딥러닝 알고리즘을 파이썬으로 쉽게 구현할 수 있도록 해주는데, Theano 기반 위에 얹어서 더 사용하기 쉽게 구현된 여러 라이브러리가 있다.\n",
        "\n",
        "* Keras - Theano 기반이지만 Torch처럼 모듈화가 잘 되어 있어서 사용하기 쉽고 최근에도 계속 업데이트되며 빠른 속도로 발전하고 있는 라이브러리.\n",
        "\n",
        "* Pylearn2 - Theano를 유지, 보수하고 있는 Montreal 대학의 Yoshua Bengio 그룹에서 개발한 Machine Learning 연구용 라이브러리\n",
        "\n",
        "* Lasagne - 가볍고 모듈화가 잘 되어 있어서 사용하기 편리함\n",
        "\n",
        "* Blocks - 위 라이브러리와 비슷하게 역시 Theano 기반으로 손쉽게 신경망 구조를 구현할 수 있도록 해주는 라이브러리\n",
        "\n",
        "* Chainer - 거의 모든 딥러닝 알고리즘을 직관적인 Python 코드로 구현할 수 있고, 자유도가 매우 높음. 대다수의 다른 라이브러리들과는 다르게 \"Define-by-Run\" 형태로 구현되어 있어서, forward 함수만 정의해주면 네트워크 구조가 자동으로 정해진다는 점이 특이하다.\n",
        "\n",
        "* nolearn - scikit-learn과 연동되며 기계학습에 유용한 여러 함수를 담고 있음.\n",
        "\n",
        "* Gensim - 큰 스케일의 텍스트 데이터를 효율적으로 다루는 것을 목표로 한 Python 기반 딥러닝 툴킷\n",
        "\n",
        "* deepnet - cudamat과 cuda-convnet 기반의 딥러닝 라이브러리\n",
        "\n",
        "* CXXNET - MShadow 라이브러리 기반으로 멀티 GPU까지 지원하며, Python 및 Matlab 인터페이스 제공\n",
        "\n",
        "* DeepPy - NumPy 기반의 라이브러리\n",
        "\n",
        "* Neon - Nervana에서 사용하는 딥러닝 프레임워크\n",
        "\n",
        "출처 : https://aikorea.org/blog/dl-libraries/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVw3nxHeF73z",
        "colab_type": "text"
      },
      "source": [
        "# 해당 알고리즘 혹은 주제의 핵심 아이디어\n",
        "\n",
        "우리는 hidden variable 이라는 것을 잘 만들어야한다. \n",
        "\n",
        "hidden variable는 사물의 특징을 잘 설명할 수 있어야하는 수학적으로만 모델링 할 수 있는 숫자라고 이해하면 된다.\n",
        "\n",
        "현실 세계에서는 카운팅할 수 있는 숫자는 아니다.\n",
        "\n",
        "우리가 고양이라는 사진을 넣으면 고양이의 특징을 잘 설명하고 있는 hidden variable에 넣게되면 우리가 만든 네트워크 구조가 계산을 해서 우리가 넣은 사진은 고양이가 가지고있는 특징들의 수치와 매우 비슷하기 때문에 \"고양이\" 라고 판별을 할 것이다.\n",
        "\n",
        "---\n",
        "\n",
        "DNN의 메인 핵심을 3가지로 나눴다.\n",
        "\n",
        "1. Representation Learning (Paradigm shift)\n",
        "2. Deep Learning(Representation Learning View)\n",
        "3. Deep Learning (Data Transformation View)\n",
        "\n",
        "Representation Learning 과정은 기계가 사물을 사물이라고 설명할 수 있는 특징점을 \"학습\"하는 것이다.\n",
        "\n",
        "Representation Learning View는 그 학습을 잘 하려고 hidden variable을 잘 설계하다보니까 얽히고 얽힌 신경망 구조가 나왔다는 것이다.\n",
        "\n",
        "Data Transformation View는 우리가 신경망을 너무 많이 설계해서 너무 얽혀서 우리가 넣는 데이터보다 신경망으로 나오는 hidden variable들이 더 많다면 고차원으로 흩어져있는  hidden variable들을 하나의 결과값으로 내는 것이 우리가 토끼사진을 넣고 토끼라는 답을 원하는 것처럼 단 하나의 답이 나오길 원하기 때문에 고차원 -> 저차원 과정을 숫자로 잘 풀어보게 되면 \n",
        "\n",
        "\n",
        "![image](https://user-images.githubusercontent.com/54893898/83869463-96b2ed00-a767-11ea-9d75-a969244c3a98.png)\n",
        "\n",
        "위와 같은 싱글 퍼셉트론이 나온다는 것이다.\n",
        "\n",
        "---\n",
        "\n",
        "![image](https://user-images.githubusercontent.com/54893898/83869648-da0d5b80-a767-11ea-982a-7809634d6afb.png)\n",
        "\n",
        "우리가 지금까지 얘기했던것을 정리해보면\n",
        "사과그림이 그려진 사진을 넣었을 때 컴퓨터로부터 \"사과\" 라는 데이터를 얻고싶다는 것이 DNN의 핵심 목표이다.\n",
        "\n",
        "그럼 사과라는 것을 Hidden variable 이라는 수학적인 변수로 나타내야 한다.\n",
        "\n",
        "hidden variable은 수많은 사과 사진 데이터로 학습되어서, 사과의 특징을 정말 잘 설명할 수 있는 변수가 된 것이다.\n",
        "\n",
        "---\n",
        "\n",
        "DNN이 우리에게 주는 의미는 이제는 Hidden variable을 잘 구축하고(network), 많은 양의 데이터를 확보할 수 있어야 한다는 것이다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6gWQ6E7CZF4",
        "colab_type": "text"
      },
      "source": [
        "# 간단한 DNN 구현해보기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CawnKBmL6lak",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 801
        },
        "outputId": "58c0cadd-076d-47fd-b257-ba0d5523c693"
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras import *\n",
        "\n",
        "\n",
        "# 이 구간은 데이터를 받아 오는곳 입니다.\n",
        "num_classes = 10\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# x_train : [60000, 28, 28]\n",
        "# y_train : [60000, ]\n",
        "# x_test  : [10000, 28, 28]\n",
        "# y_test  : [10000, ]\n",
        "\n",
        "# 데이터를 전처리 작업을 해줍니다. \n",
        "x_train = x_train.reshape(60000, 784)\n",
        "x_test  = x_test.reshape(10000, 784)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test  = x_test.astype('float32')\n",
        "\n",
        "# 데이터를 정규화 시켜주는 부분입니다.\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# 데이터를 one-hot distribution 매트릭스로 바꿔줍니다.\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test  = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "\n",
        "# DNN 모델을 디자인 하는 곳입니다.\n",
        "model = Sequential()\n",
        "model.add( Dense(512, activation='relu', input_shape=(784,)) )\n",
        "model.add( Dropout(0.2) )\n",
        "model.add( Dense(512, activation='relu') )\n",
        "model.add( Dropout(0.2) )\n",
        "model.add( Dense(num_classes, activation='softmax') )\n",
        "\n",
        "model.summary()\n",
        "\n",
        "RMS = tf.keras.optimizers.RMSprop(\n",
        "    learning_rate=0.001, rho=0.9, momentum=0.0, epsilon=1e-07, centered=False,\n",
        "    name='RMSprop'\n",
        ")\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=RMS,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "batch_size = 10\n",
        "epochs = 10\n",
        "\n",
        "# 반복적으로 훈련해주는 곳입니다.\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test))\n",
        "\n",
        "# 결과를 프린트 해주는 곳 입니다.\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:',    score[0])\n",
        "print('Test accuracy:',score[1])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60000 train samples\n",
            "10000 test samples\n",
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_24 (Dense)             (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 669,706\n",
            "Trainable params: 669,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 43s 713us/step - loss: 0.2821 - accuracy: 0.9332 - val_loss: 0.1692 - val_accuracy: 0.9631\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 43s 721us/step - loss: 0.2570 - accuracy: 0.9563 - val_loss: 0.2852 - val_accuracy: 0.9573\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 43s 715us/step - loss: 0.2783 - accuracy: 0.9607 - val_loss: 0.1881 - val_accuracy: 0.9681\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 44s 734us/step - loss: 0.2792 - accuracy: 0.9629 - val_loss: 0.2308 - val_accuracy: 0.9739\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 43s 721us/step - loss: 0.2956 - accuracy: 0.9638 - val_loss: 0.2568 - val_accuracy: 0.9725\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 42s 707us/step - loss: 0.2995 - accuracy: 0.9657 - val_loss: 0.2795 - val_accuracy: 0.9750\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 43s 711us/step - loss: 0.3113 - accuracy: 0.9671 - val_loss: 0.2832 - val_accuracy: 0.9725\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 42s 706us/step - loss: 0.3067 - accuracy: 0.9670 - val_loss: 0.3057 - val_accuracy: 0.9717\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 43s 724us/step - loss: 0.3244 - accuracy: 0.9679 - val_loss: 0.2928 - val_accuracy: 0.9723\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 43s 713us/step - loss: 0.3152 - accuracy: 0.9683 - val_loss: 0.2892 - val_accuracy: 0.9746\n",
            "Test loss: 0.289163981725335\n",
            "Test accuracy: 0.9746000170707703\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}